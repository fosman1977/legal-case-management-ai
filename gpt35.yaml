name: gpt-3.5-turbo
backend: llama-cpp
parameters:
  model: tinyllama.gguf
  context_size: 2048
  threads: 4
  temperature: 0.7
